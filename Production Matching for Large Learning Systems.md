# Production Matching for Large Learning Systems

## 摘要

20世纪70年代AI研究的核心成果之一是，为了实现卓越性能，AI系统必须拥有大量的知识。机器学习技术已经被用于自动获取知识，通常是if-then规则(产生式)的形式。不幸的是，这通常会导致效用问题，即“学习”最终会导致系统的整体减速。这是因为系统的规则越多，为了确定哪些规则是适用的，将它们与当前情况进行匹配所需的时间就越长。
为了解决这一问题，本文旨在实现产生式系统中规则数量的增加。我们在一系列不同的测试系统上测试，每个系统学习至少10万条规则。我们证明了在现有的匹配算法中，匹配代价随规则数目的增加而线性增加。这不适用于大型学习系统，因为它会导致效用问题。然后，我们研究了导致这种线性增长的原因，并开发了解决这一问题的技术。最终的结果是一个改进的匹配算法，Rete/UL，它是现有最先进的Rete匹配算法的一般扩展。与现有的匹配算法相比，Rete/UL的性能可以在更广泛的系统上很好地扩展。在所有被测试的系统中，使用Rete/UL而不是Rete显著地减少或消除了效用问题。

## 1. 引言

人类使用大量的知识，AI如果想要取得更好的性能，也就必须要使用大量的知识。而对大量的知识进行硬编码存在很多问题（如速度慢、枯燥、易错），机器学习技术被用于自动获取知识。不幸的是，这通常会导致效用问题，即“学习”最终会导致系统的整体减速。
举个例子，在许多系统中，学习规则是用于减少系统解决某一问题的基本步骤——比如通过修建搜索空间。但是为了在每一步确定那些规则是适用的，系统必须把这些规则和当前情况做匹配。在现有的技术下，随着越来越多的规则被获取，匹配器的速度会变慢，所以每一步花费的时间越来越长。由此增加的时间可能超过因为步骤减少而节省的时间，最终导致系统反而更慢了。
本研究的主题是通过改进匹配算法，来在更广泛的系统中解决这个问题。从本质上说，我们的目标是使得产生式系统可以包含更多的规则。我们在最先进的生产匹配算法做出改进，开发了一种新的匹配算法，其性能比现有算法在更广泛的系统上扩展得更好。此外，我们证明了使用这种改进的匹配算法，我们可以在一个许多机器学习系统中减少或避免效用问题。

### 1.1 以往解决效用问题的方法

以往的研究一般采用两种方法来解决由于匹配成本增加而导致的匹配速度放缓问题。一种方法是简单地减少系统知识库中的规则数量，一般是通过某种形式的选择性学习或遗忘。典型的方法有：如果学习某些规则带来的匹配器的速度变慢会导致系统整体速度的下降，那么就放弃学习这些规则；在达到某个期望的或峰值的性能水平后禁用学习组件；只学习匹配成本较低的规则；使用统计方法来确保(以高概率)只将可以真正提高性能的规则添加到知识库中。
不幸的是，这种方法本身并不适合AI的长期目标，因为在当前的匹配技术状态下，它通过排除大量知识的学习来解决问题。当一个系统学习了的规则达到某一规模时，匹配成本就会大幅增加，最终达到一个临界点，此后系统整体速度变慢。因此，有选择性的学习的方法本身就会在一定程度上阻碍对规则的学习。然而，这些方法可以由其他减少匹配成本的方法加以补充。例如，在一个只在收益大于成本时才保存规则的系统中，使用其他降低匹配成本(而不影响规则的收益)的方法将改变“收支平衡”点，从而允许系统保存和使用更多规则。
以往研究采用的第二个主要方法是降低单个规则的匹配成本，每次只采用一条规则。为此已经开发了许多技术，例如：Tambe等通过限制系统使用的表示形式，防止形成单个具有组合匹配代价的昂贵规则；Prodigy的压缩模块通过简化Prodigy/EBL生成的规则条件，降低了匹配成本；Etzioni等对许多和Prodigy/EBL相同的情形，静态和动态分析问题空间的结构，以建立更简单的匹配成本更低的规则；Cohen采用了类似的方法，只保留了少数几个搜索控制规则的条件。
这些工作有助于降低单个规则的成本，使系统能够在整体速度放缓之前学习更多的规则。不幸的是，当大量单独的低成本规则加在一起时，仍然会导致整体速度的下降。随着规则数量的增加，平均匹配成本也随之增加;这被称为平均增长效应或沼泽效应。
为了解决这一问题，本文采用了一种与上述两种方法相辅相成的新方法，考察了在不考虑单个规则成本的情况下，降低大量规则的总匹配成本这一相对未被探索的领域。某些领域可能在这里提供特殊的方法——例如，在自然语言处理中，根据所学规则所涉及的特定单词或词汇类别，我们有可能对这些规则进行索引，但是没有一个通用的方法被开发出来。

### 1.2 论文概述

由于单个廉价产生式数量的增加而引起的匹配成本的增加是本论文的重点。最终目标是支持大型的学习的产生式系统，即学习大量规则的系统。
实证研究是本文的核心内容。我们研究了许多大型的学习系统，并将它们用作我们开发和研究的算法的试验台。这些系统在不同的领域使用了不同的解决问题的技术，由具有不同研究兴趣的人编写。每个系统至少学习十万条规则。这些系统使用Soar，一个综合的解决问题和学习的架构。Soar为这项研究提供了一个有用的工具，原因有三:它提供了一种学习新规则的机制(分组)，它已经整合了一种现有的最好的匹配算法(Rete)，它有一个庞大的用户社区来提供一套测试系统。
我们对这些大型的的产生式系统的研究揭示了一些新的现象，以及对一些基于之前较小系统的观察做出的常见假设提出了质疑。现有的最好的匹配算法Rete 和Treat，在我们所有的测试系统中，都随着规则数量增加而线性减速。这种线性减速对于机器学习系统来说是一个严重的问题，因为如果学习的规则足够多，就会导致效用问题。因此，目前最好的匹配算法并不能很好地适应这些系统中规则的数量。
在Rete匹配算法中，也就是我们开发一种改进的匹配器的起点，有三个原因导致线性减速。其中两种是普遍存在的，出现在我们许多或所有测试过的系统中，并且预计也将出现在更广泛的其它大型学习系统中。
我们开发了一种改进的匹配算法，称为Rete/UL，通过在Rete中加入一些改变来避免这两个原因的放缓。对于Rete/UL，线性减速的第三个原因仍然存在于一个测试中，但它比前两个原因轻得多，而且在我们的大多数测试系统中根本不会出现。
我们通过在我们的每个测试平台系统上测量Rete/UL和基本Rete算法的性能，并比较结果，对Rete/UL进行了经验上的评估。除了一个系统外，Rete/UL在所有系统中都消除了随着规则数量增加而出现的线性减速，并且在该系统中Rete/UL显著降低了这种减速。与Rete和Treat相比，Rete/UL可以在更广泛的系统上很好地扩展。此外，在这些测试系统中，Rete/UL运行速度大约比Rete快两个数量级。
最后，我们研究匹配算法对效用问题的影响。这又是根据经验来做的，测量每个被测试的系统在学习十万条或更多规则时所达到的加速或引起的减速。实验表明使用Rete/UL而不是基础Rete算法在所有的测试系统中减少或消除了效用问题。

### 1.3 论文范围的界定

### 1.4 论文的组织

第二章介绍了基本的Rete匹配算法，这也是是本文研究的出发点。该描述采用教程风格，使用高级伪代码来说明Rete使用的主要数据结构和程序。第三章对我们用作测试的系统进行了描述，然后给出了当我们增加测试系统中的规则数量时，对基础Rete算法性能的经验观察。第4章和第5章探讨了造成这种减速的两个普遍原因，并开发了改进匹配算法的技术以避免它们。第6章给出了一些匹配成本的理论分析，并解释了我们测试的一个系统中还存在线性减速的小原因。第七章研究了匹配算法的选择对效用问题的影响，证明了改进的匹配算法在所有测试系统中减少或消除了效用问题。最后，第八章总结了本文的研究成果和贡献，并对未来的工作提出了一些有趣的方向。
我们在整篇论文中适当的点讨论相关的工作。我们已经讨论了解决效用问题的其他一些方法，以及产生式系统的其他一些工作领域。产生式匹配算法的相关工作主要在第2章和第3.4、3.6和5.8节中进行讨论。关于效用问题的相关工作主要在第7章中讨论。

## 2. 基础Rete算法

对多文章中对Rete的描述不够清楚，这也是为什么Rete算法落得一个“极复杂”的名声。为此，本文详细描述Rete。我们将首先给出一个Rete的概述，然后讨论基本的数据结构和实现它常用的程序。本文将给出许多结构和程序的高级伪代码，因此本章可以作为希望在自己的系统中实现Rete(或其他变体)的读者的指南。已经熟悉Rete的读者或只想从头到尾读这篇论文的研究贡献的读者应该略读或略过这一章。第2.6节及之后的部分讨论了Rete的高级方面，可以在第一次阅读时跳过;没有它们，论文的其余大部分内容都是可以理解的。
复习一下基本概念：

1. 工作内存是一个工作内存元素的集合，每个WME又叫一个项，这里用三元组来表示WME。
2. 产生式内存是一个产生式的集合，产生式又由条件的集合和动作的集合组成，这里也用三元组来表示条件。
3. 匹配算法的工作在于确定哪些产生式和当前工作内存相匹配，且对于某条产生式，能确定工作内存中的哪些WME匹配它的哪些条件。
4. 可以把Rete看做一个黑盒子，他接收WM和PM的改变信息，输出当前产生式的匹配情况的改变。

### 2.1 概述

Rete用一个数据流网络来表示产生式的条件。网络有两个部分。Alpha网络对WME执行常量测试，输出存放在Alpha Memory中，即每个AM中存放的是通过单个条件中的所有常量测试的WME。2.2节会讨论Alpha网络的实现。Beta网络主要包含连接节点和Beta Memory，连接节点对若干条件间的变量执行绑定的一致性测试，BM存放产生式的部分实例（即符合某条产生式的部分条件的WMEs），这些部分实例也叫令牌。
在不同的Rete实现中，Alpha网络的测试范围可能不同，但是它总是只涉及单个条件的测试，而Beta网络中的测试涉及两个或多个条件。
可以和关系型数据库做类比。可以把当前的工作内存看作一个关系，把每一条产生式看作一条查询。在某一条件中的常量测试代表该关系上的SELECT操作，对系统的不同的条件c~i~，都有一个AM来存储其SELECT对应的结果r(c~i~)。令P为一条带n个条件(c~1~...c~k~)的产生式，那么P和WM的匹配结果为r(c~1~)到r(c~k~)的笛卡尔积，而连接操作执行的就是变量绑定的一致性检查。Beta网络中的连接节点执行这些连接操作，每个BM存储的就是类似形式的笛卡尔积。
每当WM中发生改变，我们就更新这些SELECT和JOIN的结果。流程如下：工作内存的改变信息沿着Alpha网络传递，某些AM会更新。这些更新会传播给它们相邻的连接节点并激活它们。如果有新的部分实例被创建的的话就把它加入BM中，并沿着Beta网络传播以激活其它节点。每当有信息传播到网络的底部，就说明某条产生式的条件得到了完全匹配。这通常是通过在网络底部为每一条产生式创建一个特殊的节点来实现的。
Rete算法的大部分代码都是用于处理各种节点的激活。AM-Node节点激活的处理如下：把一个WME加入该AM，然后再把它传给该AM的后继连接节点。BM-Node节点激活的处理如下：把一个令牌加入该BM，然后再把它传给该BM的孩子连接节点。一般来说，某节点的激活如果来自Beta网络中的另一节点，该激活称为左激活；如果来自某AM，该激活称为右激活。
为不同类型节点设计的激活程序是不同的。
Rete算法有两个重要特性使得它比简单的匹配算法要快得多。第一点是状态保存，第二点是带有相似条件的产生式共享节点。
在接下来的章节中，我们会更详细地介绍Rete算法，给出其基本数据结构和程序的伪代码。在附录A中给出了完整的伪代码，它包括了后面章节中提到的一些改进。
一个系统的Rete模块有四个入口：add-wme,remove-wme,add-production,remove-production。我们会从调用一个add-wme会发生什么开始：2.2节描述了Alpha网络怎么做，2.3节描述了AM和BM怎么做，2.4节描述了连接节点怎么做。我们在2.5节讨论了remove-wme，在2.6节讨论了add-production和remove-production。

### 2.2 Alpha网络的实现

当一个WME被加入到WM时，alpha网络对它执行必要的常量测试，并把它存入合适的AM中。有几种方式来找到合适的AM。

#### 2.2.1 数据流网络

#### 2.2.2 带哈希的数据流网络

上面的数据流网络的实现在大型系统中有一个严重的缺陷。即当一个节点的扇出过大时，会有很多工作是浪费的。
解决这个问题的一个直接的想法就是用一个带哈希表的特殊节点来取代大扇出的节点，根据哈希表来确定激活的信息需要沿着哪条路劲往下传。

#### 2.2.3 穷举的哈希表查找

当WMEs用三元组表示时，只用少量的哈希表查找就可以实现大多数的alpha网络。现在假设所有的常数检验都是相等性检验。注意：对任一给定的WME，它能去的AM最多只有8个。我们为系统中所有的AM维护一个指针，用一个哈希表来存放这些指针，根据测试的特定值建立索引。执行Alpha网络就是做8次哈希表的查找。
无论是2.2.2节中的数据流加上哈希的实现还是2.2.3节中的穷举的哈希表查找的实现，alpha网络都是高效的，而Beta网络承担了大部分的匹配成本。所以会更多地介绍Beta网络。

### 2.3 Memory节点的实现

下面来讨论AM和BM的实现。回想一下，AM中存放的是WMEs的集合，BM中存放的是令牌的集合，令牌是一个WMEs的序列。
Memory节点的实现有很多方式，可以按照两个标准来对它们进行分类：

1. 如何构建（WMEs或令牌的）集合
2. 如何表示令牌（一个WMEs的序列）

对于第一个问题，最简单的实现是不在集合上加任何特殊结构，即用list来表示集合，里面的项无序。然而，如果在Memory中加上索引结构的话，连接操作会更高效。最常见的索引结构是哈希表。但是，如果要在每个Memory节点中存放一个哈希表，那么它的规模怎么选择？我们可以根据Memory中项的增减来动态调整哈希表的大小，但是这会把一个昂贵的代码块加入到一个简单的程序。
通常的解决办法是在一个大的全局哈希表中为所有BM中的令牌建立索引，在另一个大的全局哈希表中为所有AM中的WMEs建立索引。全局哈希表的规模提前确定，通常为几千。哈希函数是与来自令牌（或WME的）变量绑定和节点自身相关。这个想法是为了尽量减少碰撞：如果我们固定Memory节点并改变变量绑定，哈希函数的结果应该均匀地分布在各个桶中;同样的，如果我们固定变量绑定并改变Memory节点，哈希函数的结果也应该均匀地分布在各个桶中。
现在关注第二个问题，如何表示令牌（一个WMEs的序列）？主要有两种可能，一个序列可能会用数组表示或者用列表表示。使用数组可以做到随机访问，但是会存储大量的冗余信息，占用更多的空间。一个令牌可以用一个链表来表示。
总结一下，使用数组形式占用更多的空间，并且在激活BM时花费更多的时间来创建一个令牌。但它能做到对某一序列元素更快地访问。
下面给出伪代码，为了简单起见，这里用了list形式的令牌和无索引的Memory节点。

#### 2.3.1 AM的实现

#### 2.3.2 BM的实现

#### 2.3.3 P-节点的实现

### 2.4 连接节点的实现

### 2.5 WMEs的移除

当一个WME从工作内存中移除时，我们需要通过移除包含它的项来更新AM和BM。有几种方式可以做到这一点。
在最初始的Rete算法中，使用的是基于再匹配的移除，这里对某个WME的移除并没有用到之前添加它时保存的信息。至少有三种处理移除的方式可以利用这些信息：

